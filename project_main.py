import time
import pygame
import cv2
import threading
import json

# å‡è¨­ä½ å·²æœ‰é€™äº›æ¨¡çµ„
from func.warp_rt import WarpProcessor
from func.yolov7_rt import YoloV7Detector
from func.mediapipe_rt import MediaPipeHandTracker
from func.step_guide_rt import StepGuide
from func.pygame_rt import (
    draw_guidance_np_center,
    play_init_sound, play_step_sound,
    play_end_sound, play_error_sound
)

# è®€å–è…³æœ¬é…ç½®ï¼ˆç”¨æ–¼éŸ³æ•ˆï¼‰
with open(r"func\script.json", "r", encoding="utf-8") as f:
    _cfg = json.load(f)
INIT_AUDIO  = _cfg.get("init",  [{}])[0].get("audio", "")
END_AUDIO   = _cfg.get("end",   [{}])[0].get("audio", "")
ERROR_AUDIO = _cfg.get("error", [{}])[0].get("audio", "")

# ===== äº’å‹•åœ“å½¢æŒ‰éˆ•è¨­å®š ======================================
BTN_RADIUS    = 40
BTN_CENTERS   = [(140, 40), (1140, 40)]   # è‹¥è§£æåº¦æ”¹è®Šè¨˜å¾—èª¿
HOLD_SECONDS  = 1.0                       # é›†æ°£æ»¿æ ¼æ™‚é–“
DECAY_SECONDS = 0.5                       # é›¢é–‹å¾Œè¡°æ¸›åˆ° 0 çš„æ™‚é–“
# ============================================================


def run_game(student_data: dict, db) -> float:
    """
    åŸ·è¡Œ Pygame çµ„è£éŠæˆ²ä¸»ç¨‹å¼ã€‚
    Args:
        student_data (dict): ç™»å…¥å­¸ç”Ÿè³‡è¨Šï¼ˆstu_name, stu_class, ...ï¼‰
    Returns:
        float: éŠç©ç§’æ•¸
    """
    print(f"ğŸ® é–‹å§‹éŠæˆ²ï¼Œç©å®¶ï¼š{student_data}")

    # ---------- 0. åˆå§‹åŒ–éŸ³æ•ˆèˆ‡æ™‚é–“è¨ˆæ™‚ ----------
    init_sound_played = False
    end_sound_played = False

    # ---------- 1. å»ºç«‹ stop_event for Pygame thread ----------
    stop_event = threading.Event()  # ç”¨ä¾†é€šçŸ¥ show_aruco åŸ·è¡Œç·’çµæŸ

    # ---------- 2. åˆå§‹åŒ–æ§åˆ¶ç‹€æ…‹èˆ‡æ¨¡çµ„ ----------
    hold_timer = [0.0] * len(BTN_CENTERS)
    ready_flag = [True] * len(BTN_CENTERS)
    progress   = [0.0] * len(BTN_CENTERS)

    warp_proc = WarpProcessor(1280, 720, BTN_CENTERS, BTN_RADIUS)
    yolo = YoloV7Detector(r"func\weight\exp_55best.pt", r"func\all_step_class.txt")
    mp_tracker = MediaPipeHandTracker(
        max_num_hands=2, model_complexity=1,
        detection_confidence=0.6, tracking_confidence=0.6
    )
    step_guide = StepGuide(r"func\script.json")

    # ---------- 3. æ–‡å­—é¡¯ç¤ºè¨­å®š ----------
    text_settings = {
        "font_path": r"src/ui/font/BpmfGenSenRounded-R.ttf",
        "font_size": 40,
        "color": (255, 255, 255),
        "pos": {
            "play_time": (200, 0),                                 # å·¦ä¸Šè§’ï¼šéŠç©æ™‚é–“
            "step_id":    (warp_proc.SCREEN_WIDTH // 2, 0),       # ä¸­ä¸Šï¼šç•¶å‰æ­¥é©Ÿ ID
            "stu_name":   (warp_proc.SCREEN_WIDTH - 200, 0)       # å³ä¸Šï¼šå­¸ç”Ÿåç¨±
        }
    }

    # ---------- 4. å•Ÿå‹•ç¬¬äºŒè¢å¹• Pygame é¡¯ç¤º ----------
    start_time = time.time()
    pygame_thread = threading.Thread(
        target=warp_proc.show_aruco_on_second_screen,
        args=(
            stop_event,
            student_data.get("stu_name", ""),
            start_time,
            text_settings
        ),
        daemon=True
    )
    pygame_thread.start()

    # ---------- 3. å•Ÿå‹•æ”å½±æ©Ÿ ----------
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ ç„¡æ³•é–‹å•Ÿç›¸æ©Ÿ")
        return 0.0

    print("â–¶ï¸ æŒ‰ 'r' é‡æ–°æ ¡æ­£ï¼ŒæŒ‰ 'q' é›¢é–‹")
    last_t = time.perf_counter()

    # ========== 4. ä¸»è™•ç†è¿´åœˆï¼ˆæ ¡æ­£ã€å¼•å°ã€äº’å‹•ï¼‰ ==========
    while True:
        # ---------- 4-1. è®€å–èˆ‡é¡¯ç¤ºé¡åƒç•«é¢ ----------
        ret, frame = cap.read()
        if not ret:
            continue
        frame = cv2.flip(frame, -1)
        cv2.imshow("Camera Debug", frame)

        # ---------- 4-2. æ ¡æ­£ç•«é¢ ----------
        if not warp_proc.calibrated:
            if warp_proc.calibrate_once(frame):
                print("âœ… æ ¡æ­£æˆåŠŸ")
            if cv2.waitKey(1) & 0xFF == ord('q'):
                stop_event.set(); break
            continue

        # ---------- 4-3. é€è¦–è½‰æ› + YOLO åµæ¸¬ ----------
        warped = warp_proc.warp_frame(frame)
        if warped is None:
            continue
        guide_vis = warped.copy()

        if warp_proc.current_animation_frames:
            ani_h = warp_proc.current_animation_frames[0].get_height()
            ani_w = warp_proc.current_animation_frames[0].get_width()
            x = (warp_proc.SCREEN_WIDTH - ani_w) // 2
            cv2.rectangle(warped, (x, 10), (x+ani_w, 10+ani_h), (0, 0, 0), -1)

        detections = yolo.detect(warped)
        for (xyxy, label) in detections:
            x1, y1, x2, y2 = map(int, xyxy)
            cv2.rectangle(guide_vis, (x1, y1), (x2, y2), (255, 0, 0), 2)
            cv2.putText(guide_vis, label, (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)

        # ---------- 4-4. æ‰‹éƒ¨è¿½è¹¤ + çµ„è£æ­¥é©Ÿåˆ†æ ----------
        guide_vis, hand_lms, handed_list = mp_tracker.process_frame(
            guide_vis, draw_landmarks=True, debug_info=False
        )
        draw_info = step_guide.update_and_get_draw_info(
            detections, hand_lms, handed_list
        )
        # å‚³éç•¶å‰æ­¥é©Ÿ ID
        cur = step_guide.get_current_step()
        draw_info["step_id"] = cur.get("id") if cur else None

        # ---------- 4-5. æ’­æ”¾é¦–æ¬¡ init éŸ³æ•ˆ ----------
        if (not init_sound_played
            and step_guide.current_index == 0
            and draw_info['cuni_bbox'] is not None
            and draw_info['cint_bbox'] is not None):
            play_init_sound(INIT_AUDIO)
            init_sound_played = True

        # ---------- 4-6. é›†æ°£æŒ‰éˆ•é‚è¼¯ ----------
        dt = time.perf_counter() - last_t
        last_t = time.perf_counter()
        tips = [(pt[0], pt[1]) for hand in hand_lms for pt in hand] if hand_lms else []

        for i, center in enumerate(BTN_CENTERS):
            inside = any(
                (tx - center[0])**2 + (ty - center[1])**2 <= BTN_RADIUS**2
                for tx, ty in tips
            )
            if inside:
                cv2.circle(guide_vis, center, BTN_RADIUS, (255, 255, 0), 2)
                if ready_flag[i]:
                    hold_timer[i] += dt
                    progress[i] = min(1.0, hold_timer[i] / HOLD_SECONDS)
                    if hold_timer[i] >= HOLD_SECONDS:
                        if step_guide.check_assembly_complete(detections):
                            cur_step = step_guide.get_current_step()
                            if cur_step and cur_step.get("audio"):
                                play_step_sound(cur_step["audio"])
                            step_guide.unlock_for_next_step()
                        else:
                            play_error_sound(ERROR_AUDIO)
                        ready_flag[i] = False
                        hold_timer[i] = progress[i] = 1.0
            else:
                hold_timer[i] = 0.0
                ready_flag[i] = True
                progress[i] = max(0.0, progress[i] - dt / DECAY_SECONDS)

        warp_proc.update_button_progress(progress)

        # ---------- 4-7. è¦–è¦ºåŒ–å°å¼•èˆ‡å‹•ç•« ----------
        if draw_info['cuni_draw_pos'] and draw_info['cint_draw_pos']:
            guide_vis = draw_guidance_np_center(
                guide_vis,
                draw_info['cuni_draw_pos'], draw_info['cuni_draw_radius'],
                draw_info['cint_draw_pos'], draw_info['cint_draw_radius']
            )

        cur_step = step_guide.get_current_step()
        if cur_step and cur_step.get("animation"):
            warp_proc.update_animation(cur_step["animation"])

        cv2.imshow("build guide", guide_vis)
        warp_proc.update_proj_draw_info(draw_info)

        # ---------- 4-8. å…¨éƒ¨å®Œæˆ ----------
        if cur_step is None and not end_sound_played:
            play_end_sound(END_AUDIO)
            end_sound_played = True
            time.sleep(3)
            stop_event.set()
            break

        # ---------- 4-9. æ‰‹å‹•éµç›¤æ“ä½œ ----------
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            stop_event.set(); break
        elif key == ord('r'):
            print("ğŸ” é‡æ–°è§¸ç™¼æ ¡æ­£")
            warp_proc.calibrated = False

    # ---------- 5. æ”¶å°¾è™•ç†ï¼ˆé‡‹æ”¾è³‡æºï¼‰ ----------
    cap.release()
    cv2.destroyAllWindows()
    pygame_thread.join()

    play_time = time.time() - start_time
    print(f"â±ï¸ éŠæˆ²å®Œæˆï¼ŒéŠç©æ™‚é•·ï¼š{play_time:.2f} ç§’")
    # ---------- 6. å¯«å…¥è³‡æ–™åº« Practice ----------
    try:
        stu_uuid     = student_data.get("stu_uuid")
        stu_name     = student_data.get("stu_name")

        # æ™‚é–“è³‡è¨Š
        start_dt = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(start_time))
        end_dt   = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(time.time()))
        play_sec = int(play_time)

        db.cursor.execute(
            """
            INSERT INTO Practice (stu_name, stu_uuid, game_time, practice_start_date, practice_end_date)
            VALUES (?, ?, ?, ?, ?)
            """,
            (stu_name, stu_uuid, play_sec, start_dt, end_dt)
        )
        db.conn.commit()
        print("âœ… å·²å¯«å…¥ Practice éŠç©ç´€éŒ„")
    except Exception as e:
        print(f"âŒ å¯«å…¥ Practice æ™‚å‡ºéŒ¯: {e}")

    return play_time
